import asyncio
from dotenv import load_dotenv
import os
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from transformers import AutoModelForCausalLM, AutoTokenizer
from database import init_db, get_history, update_history, clear_history
import torch

load_dotenv()
BOT_TOKEN = os.getenv("BOT_TOKEN")
HISTORY_LIMIT = int(os.getenv("HISTORY_LIMIT", 10))

if not BOT_TOKEN:
    raise ValueError("–¢–æ–∫–µ–Ω –±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env!")

model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype=torch.float16,
    use_flash_attention_2=False
)

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

@dp.message(Command("start"))
async def start(message: types.Message):
    await message.answer(
            "üèõÔ∏è –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ 'Reload: Ancient World' - —Ç–µ–∫—Å—Ç–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥—Ä–µ–≤–Ω–µ–≥–æ –º–∏—Ä–∞! üèõÔ∏è\n\n"
        "–¢—ã - –ø—Ä–∞–≤–∏—Ç–µ–ª—å –≤–µ–ª–∏–∫–æ–≥–æ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–∞ –≤ —ç–ø–æ—Ö—É –ø–µ—Ä–≤—ã—Ö —Ü–∏–≤–∏–ª–∏–∑–∞—Ü–∏–π. –ü–µ—Ä–µ–¥ —Ç–æ–±–æ–π —Å—Ç–æ—è—Ç –≤–∞–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:\n"
        "- –í–µ—Å—Ç–∏ –ª–∏ –≤–æ–π–Ω—ã –∏–ª–∏ –∑–∞–∫–ª—é—á–∞—Ç—å —Å–æ—é–∑—ã?\n"
        "- –†–∞–∑–≤–∏–≤–∞—Ç—å –ª–∏ –Ω–∞—É–∫–∏ –∏–ª–∏ —É–∫—Ä–µ–ø–ª—è—Ç—å –∞—Ä–º–∏—é?\n"
        "- –°—Ç—Ä–æ–∏—Ç—å –ª–∏ –≤–µ–ª–∏–∫–∏–µ –ø–∞–º—è—Ç–Ω–∏–∫–∏ –∏–ª–∏ –∫–æ–ø–∏—Ç—å –∑–æ–ª–æ—Ç–æ?\n\n"
        "–ö–∞–∂–¥—ã–π —Ç–≤–æ–π –≤—ã–±–æ—Ä –≤–ª–∏—è–µ—Ç –Ω–∞ —Å—É–¥—å–±—É —Ç–≤–æ–µ–≥–æ –Ω–∞—Ä–æ–¥–∞.\n\n"
        "–ù–∞—á–Ω—ë–º –∏–≥—Ä—É!\n"
        "–ß—Ç–æ–±—ã —Å–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ - /new")

@dp.message(Command("new"))
async def new_chat(message: types.Message):
    await clear_history(message.from_user.id)
    await message.answer("‚öîÔ∏è –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ —Å–±—Ä–æ—à–µ–Ω!‚öîÔ∏è")

@dp.message(F.text)
async def handle_message(message: types.Message):
    user_id = message.from_user.id
    try:
        history = await get_history(user_id)
        context = '\n'.join(history + [f"User: {message.text}"]) + "\nAssistant:"
        inputs = tokenizer(context, return_tensors="pt").to(model.device)
        outputs = model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=True,
            temperature=0.7,
            top_p=0.95,
            eos_token_id=tokenizer.eos_token_id,
            pad_token_id=tokenizer.eos_token_id
        )
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        assistant_reply = response[len(context):].strip().split('\n')[0]
        await update_history(user_id, message.text, assistant_reply, HISTORY_LIMIT)
        await message.answer(assistant_reply)
    except Exception as e:
        await message.answer(f"–û—à–∏–±–∫–∞: {str(e)}")

async def main():
    await init_db()
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
